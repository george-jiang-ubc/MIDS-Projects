{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iDI5luY_5Pj"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Suz-2KWHeqX4",
    "outputId": "4300b608-07ae-463c-8f13-f763fc50da84"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "dY6gZ334AdOb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_train data holds 307511 obs and 122 variables\n",
      "app_test data holds 48744 obs and 121 variables\n",
      "bureau data holds 1716428 obs and 17 variables\n",
      "bureau_bal data holds 27299925 obs and 3 variables\n",
      "cc_bal data holds 3840312 obs and 23 variables\n",
      "install_pmts data holds 13605401 obs and 8 variables\n",
      "pos_cash_bal data holds 10001358 obs and 8 variables\n",
      "prev_app data holds 1670214 obs and 37 variables\n"
     ]
    }
   ],
   "source": [
    "# notebook settings\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "df = pd.read_csv('application_train.csv')\n",
    "test = pd.read_csv('application_test.csv')\n",
    "bureau = pd.read_csv('bureau.csv')\n",
    "bureau_bal = pd.read_csv('bureau_balance.csv')\n",
    "cc_bal = pd.read_csv('credit_card_balance.csv')\n",
    "install_pmts = pd.read_csv('installments_payments.csv')\n",
    "pos_cash_bal = pd.read_csv('POS_CASH_balance.csv')\n",
    "prev_app = pd.read_csv('previous_application.csv')\n",
    "print(\"app_train data holds {} obs and {} variables\".format(df.shape[0], df.shape[1]))\n",
    "print(\"app_test data holds {} obs and {} variables\".format(test.shape[0], test.shape[1]))\n",
    "print(\"bureau data holds {} obs and {} variables\".format(bureau.shape[0], bureau.shape[1]))\n",
    "print(\"bureau_bal data holds {} obs and {} variables\".format(bureau_bal.shape[0], bureau_bal.shape[1]))\n",
    "print(\"cc_bal data holds {} obs and {} variables\".format(cc_bal.shape[0], cc_bal.shape[1]))\n",
    "print(\"install_pmts data holds {} obs and {} variables\".format(install_pmts.shape[0], install_pmts.shape[1]))\n",
    "print(\"pos_cash_bal data holds {} obs and {} variables\".format(pos_cash_bal.shape[0], pos_cash_bal.shape[1]))\n",
    "print(\"prev_app data holds {} obs and {} variables\".format(prev_app.shape[0], prev_app.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of integer features: 4\n",
      "# of float features: 15\n",
      "# of str features: 16\n"
     ]
    }
   ],
   "source": [
    "int_features = prev_app.iloc[:, 2:].select_dtypes('int64').columns.values\n",
    "float_features = prev_app.iloc[:, 2:].select_dtypes('float64').columns.values\n",
    "str_features = prev_app.iloc[:, 2:].select_dtypes('O').columns.values\n",
    "\n",
    "print('# of integer features:', len(int_features))\n",
    "print('# of float features:', len(float_features))\n",
    "print('# of str features:', len(str_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cash loans        43.5528\n",
      "Consumer loans    42.4807\n",
      "Revolving loans   11.2538\n",
      "XNA                0.0202\n",
      "Name: NAME_CONTRACT_TYPE, dtype: float64\n",
      "TUESDAY     14.8633\n",
      "WEDNESDAY   14.8570\n",
      "MONDAY      14.7724\n",
      "FRIDAY      14.6844\n",
      "THURSDAY    14.5126\n",
      "SATURDAY    14.0193\n",
      "SUNDAY       9.5985\n",
      "Name: WEEKDAY_APPR_PROCESS_START, dtype: float64\n",
      "Y   96.8138\n",
      "N    0.4938\n",
      "Name: FLAG_LAST_APPL_PER_CONTRACT, dtype: float64\n",
      "XAP                                53.7547\n",
      "XNA                                39.4959\n",
      "Repairs                             1.3846\n",
      "Other                               0.9093\n",
      "Urgent needs                        0.4901\n",
      "Buying a used car                   0.1683\n",
      "Building a house or an annex        0.1569\n",
      "Everyday expenses                   0.1408\n",
      "Medicine                            0.1267\n",
      "Payments on other loans             0.1125\n",
      "Education                           0.0916\n",
      "Journey                             0.0722\n",
      "Purchase of electronic equipment    0.0618\n",
      "Buying a new car                    0.0590\n",
      "Wedding / gift / holiday            0.0560\n",
      "Buying a home                       0.0504\n",
      "Car repairs                         0.0464\n",
      "Furniture                           0.0436\n",
      "Buying a holiday home / land        0.0311\n",
      "Business development                0.0248\n",
      "Gasification / water supply         0.0175\n",
      "Buying a garage                     0.0079\n",
      "Hobby                               0.0032\n",
      "Money for a third person            0.0015\n",
      "Refusal to name the goal            0.0009\n",
      "Name: NAME_CASH_LOAN_PURPOSE, dtype: float64\n",
      "Approved       60.4034\n",
      "Canceled       18.4289\n",
      "Refused        16.9351\n",
      "Unused offer    1.5402\n",
      "Name: NAME_CONTRACT_STATUS, dtype: float64\n",
      "Cash through the bank                       60.2153\n",
      "XNA                                         36.5517\n",
      "Non-cash from your account                   0.4773\n",
      "Cashless from the account of the employer    0.0632\n",
      "Name: NAME_PAYMENT_TYPE, dtype: float64\n",
      "XAP      78.8319\n",
      "HC       10.2091\n",
      "LIMIT     3.2439\n",
      "SCO       2.1828\n",
      "CLIENT    1.5402\n",
      "SCOFR     0.7464\n",
      "XNA       0.3055\n",
      "VERIF     0.2060\n",
      "SYSTEM    0.0418\n",
      "Name: CODE_REJECT_REASON, dtype: float64\n",
      "NaN               47.7972\n",
      "Unaccompanied     29.6529\n",
      "Family            12.4248\n",
      "Spouse, partner    3.9075\n",
      "Children           1.8391\n",
      "Other_B            1.0268\n",
      "Other_A            0.5288\n",
      "Group of people    0.1305\n",
      "Name: NAME_TYPE_SUITE, dtype: float64\n",
      "Repeater    71.7339\n",
      "New         17.5576\n",
      "Refreshed    7.9030\n",
      "XNA          0.1131\n",
      "Name: NAME_CLIENT_TYPE, dtype: float64\n",
      "XNA                        55.3946\n",
      "Mobile                     13.0916\n",
      "Consumer Electronics        7.0831\n",
      "Computers                   6.1622\n",
      "Audio/Video                 5.7935\n",
      "Furniture                   3.1260\n",
      "Photo / Cinema Equipment    1.4577\n",
      "Construction Materials      1.4562\n",
      "Clothing and Accessories    1.3723\n",
      "Auto Accessories            0.4300\n",
      "Jewelry                     0.3665\n",
      "Homewares                   0.2926\n",
      "Medical Supplies            0.2239\n",
      "Vehicles                    0.1963\n",
      "Sport and Leisure           0.1737\n",
      "Gardening                   0.1554\n",
      "Other                       0.1488\n",
      "Office Appliances           0.1359\n",
      "Tourism                     0.0967\n",
      "Medicine                    0.0903\n",
      "Direct Sales                0.0260\n",
      "Fitness                     0.0122\n",
      "Additional Service          0.0075\n",
      "Education                   0.0062\n",
      "Weapon                      0.0045\n",
      "Insurance                   0.0037\n",
      "House Construction          0.0001\n",
      "Animals                     0.0001\n",
      "Name: NAME_GOODS_CATEGORY, dtype: float64\n",
      "POS     40.2587\n",
      "Cash    26.8909\n",
      "XNA     21.6863\n",
      "Cards    8.4469\n",
      "Cars     0.0248\n",
      "Name: NAME_PORTFOLIO, dtype: float64\n",
      "XNA       61.9697\n",
      "x-sell    26.5835\n",
      "walk-in    8.7543\n",
      "Name: NAME_PRODUCT_TYPE, dtype: float64\n",
      "Credit and cash offices      41.9457\n",
      "Country-wide                 28.8209\n",
      "Stone                        12.3561\n",
      "Regional / Local              6.3229\n",
      "Contact center                4.1538\n",
      "AP+ (Cash loan)               3.3235\n",
      "Channel of corporate sales    0.3583\n",
      "Car dealer                    0.0263\n",
      "Name: CHANNEL_TYPE, dtype: float64\n",
      "XNA                    49.8547\n",
      "Consumer electronics   23.2031\n",
      "Connectivity           16.0816\n",
      "Furniture               3.3703\n",
      "Construction            1.7351\n",
      "Clothing                1.3953\n",
      "Industry                1.1183\n",
      "Auto technology         0.2907\n",
      "Jewelry                 0.1578\n",
      "MLM partners            0.0708\n",
      "Tourism                 0.0299\n",
      "Name: NAME_SELLER_INDUSTRY, dtype: float64\n",
      "XNA          30.1332\n",
      "middle       22.4613\n",
      "high         20.5853\n",
      "low_normal   18.7654\n",
      "low_action    5.3624\n",
      "Name: NAME_YIELD_GROUP, dtype: float64\n",
      "Cash                             16.6619\n",
      "POS household with interest      15.3588\n",
      "POS mobile with interest         12.8564\n",
      "Cash X-Sell: middle               8.3827\n",
      "Cash X-Sell: low                  7.5883\n",
      "Card Street                       6.5591\n",
      "POS industry with interest        5.7581\n",
      "POS household without interest    4.8303\n",
      "Card X-Sell                       4.6947\n",
      "Cash Street: high                 3.4746\n",
      "Cash X-Sell: high                 3.4549\n",
      "Cash Street: middle               2.0192\n",
      "Cash Street: low                  1.9712\n",
      "POS mobile without interest       1.4030\n",
      "POS other with interest           1.3912\n",
      "POS industry without interest     0.7342\n",
      "POS others without interest       0.1489\n",
      "NaN                               0.0202\n",
      "Name: PRODUCT_COMBINATION, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in str_features:\n",
    "    print(prev_app[i].value_counts(dropna=False) / len(bureau) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app['APPROVED'] = prev_app['NAME_CONTRACT_STATUS']=='Approved'\n",
    "prev_app['REFUSED'] = prev_app['NAME_CONTRACT_STATUS']=='Refused'\n",
    "prev_app['HIGH_INTEREST'] = prev_app['NAME_YIELD_GROUP']=='high'\n",
    "prev_app['LOW_INTEREST'] = prev_app['NAME_YIELD_GROUP'].isin(['low_normal','low_action'])\n",
    "prev_app['NEW'] = prev_app['NAME_CLIENT_TYPE'].isin(['New'])\n",
    "prev_app['REPEAT'] = prev_app['NAME_CLIENT_TYPE'].isin(['Repeater','Refreshed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive Correlations:\n",
      " NEW                         0.0057\n",
      "HIGH_INTEREST               0.0166\n",
      "DAYS_TERMINATION            0.0170\n",
      "DAYS_LAST_DUE               0.0175\n",
      "DAYS_LAST_DUE_1ST_VERSION   0.0180\n",
      "RATE_INTEREST_PRIVILEGED    0.0286\n",
      "CNT_PAYMENT                 0.0305\n",
      "DAYS_DECISION               0.0399\n",
      "REFUSED                     0.0545\n",
      "TARGET                      1.0000\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Most Negative Correlations:\n",
      " APPROVED                  -0.0492\n",
      "LOW_INTEREST              -0.0344\n",
      "DAYS_FIRST_DRAWING        -0.0312\n",
      "HOUR_APPR_PROCESS_START   -0.0278\n",
      "RATE_DOWN_PAYMENT         -0.0261\n",
      "AMT_DOWN_PAYMENT          -0.0169\n",
      "AMT_ANNUITY               -0.0149\n",
      "DAYS_FIRST_DUE            -0.0067\n",
      "REPEAT                    -0.0058\n",
      "AMT_APPLICATION           -0.0056\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "prev_app2=prev_app\n",
    "df2 = df[['SK_ID_CURR','TARGET']]\n",
    "prev_app2 = prev_app2.merge(df2, on = ['SK_ID_CURR'], how = 'left')\n",
    "correlations = prev_app2.corr()['TARGET'].sort_values()\n",
    "\n",
    "print('Most Positive Correlations:\\n', correlations.tail(10))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1670214, 19)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect\n",
    "\n",
    "B = prev_app\n",
    "B2 = prev_app.SK_ID_CURR\n",
    "\n",
    "# Feature: Total # of Pre App\n",
    "grp = B[['SK_ID_CURR', 'SK_ID_PREV']].groupby(by = ['SK_ID_CURR'])['SK_ID_PREV'].count().reset_index().rename(index=str, columns={'SK_ID_PREV': 'PRE_APP_COUNT'})\n",
    "B2 = B2.to_frame().merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of Approved Loans\n",
    "grp = B[['SK_ID_CURR', 'APPROVED']].groupby(by = ['SK_ID_CURR'])['APPROVED'].sum().reset_index().rename(index=str, columns={'APPROVED': 'APPROVED_LOAN_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of REFUSED Loans\n",
    "grp = B[['SK_ID_CURR', 'REFUSED']].groupby(by = ['SK_ID_CURR'])['REFUSED'].sum().reset_index().rename(index=str, columns={'REFUSED': 'REFUSED_LOAN_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of LOW INTEREST Loans\n",
    "grp = B[['SK_ID_CURR', 'LOW_INTEREST']].groupby(by = ['SK_ID_CURR'])['LOW_INTEREST'].sum().reset_index().rename(index=str, columns={'LOW_INTEREST': 'LOW_INTEREST_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of HIGH INTEREST Loans\n",
    "grp = B[['SK_ID_CURR', 'HIGH_INTEREST']].groupby(by = ['SK_ID_CURR'])['HIGH_INTEREST'].sum().reset_index().rename(index=str, columns={'HIGH_INTEREST': 'HIGH_INTEREST_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of NEW Loans\n",
    "grp = B[['SK_ID_CURR', 'NEW']].groupby(by = ['SK_ID_CURR'])['NEW'].sum().reset_index().rename(index=str, columns={'NEW': 'NEW_LOAN_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of REPEATING Loans\n",
    "grp = B[['SK_ID_CURR', 'REPEAT']].groupby(by = ['SK_ID_CURR'])['REPEAT'].sum().reset_index().rename(index=str, columns={'REPEAT': 'REPEAT_LOAN_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of REJECT REASONS\n",
    "grp = B[['SK_ID_CURR', 'CODE_REJECT_REASON']].groupby(by = ['SK_ID_CURR'])['CODE_REJECT_REASON'].nunique().reset_index().rename(index=str, columns={'CODE_REJECT_REASON': 'REJECT_REASON_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of Product Combinations\n",
    "grp = B[['SK_ID_CURR', 'PRODUCT_COMBINATION']].groupby(by = ['SK_ID_CURR'])['PRODUCT_COMBINATION'].nunique().reset_index().rename(index=str, columns={'PRODUCT_COMBINATION': 'TOTAL_PRODUCT_COMBO'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "B2['APPROVED_RATIO'] = B2['APPROVED_LOAN_COUNT']/B2['PRE_APP_COUNT']\n",
    "B2['REFUSED_RATIO'] = B2['REFUSED_LOAN_COUNT']/B2['PRE_APP_COUNT']\n",
    "B2['APPROVE_REFUSE_RATIO'] = B2['APPROVED_LOAN_COUNT']/B2['REFUSED_LOAN_COUNT']\n",
    "\n",
    "B2['LOW_INT_RATIO'] = B2['LOW_INTEREST_COUNT']/B2['PRE_APP_COUNT']\n",
    "B2['HIGH_INT_RATIO'] = B2['HIGH_INTEREST_COUNT']/B2['PRE_APP_COUNT']\n",
    "B2['LOW_HIGH_INT_RATIO'] = B2['LOW_INTEREST_COUNT']/B2['HIGH_INTEREST_COUNT']\n",
    "\n",
    "B2['NEW_RATIO'] = B2['NEW_LOAN_COUNT']/B2['PRE_APP_COUNT']\n",
    "B2['REPEAT_RATIO'] = B2['REPEAT_LOAN_COUNT']/B2['PRE_APP_COUNT']\n",
    "B2['NEW_REPEAT_RATIO'] = B2['NEW_LOAN_COUNT']/B2['REPEAT_LOAN_COUNT']\n",
    "\n",
    "gc.collect()\n",
    "print(B2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1670214, 26)\n"
     ]
    }
   ],
   "source": [
    "# Feature: Avg Payment CNT\n",
    "grp = B[['SK_ID_CURR', 'CNT_PAYMENT']].groupby(by = ['SK_ID_CURR'])['CNT_PAYMENT'].mean().reset_index().rename(index=str, columns={'CNT_PAYMENT': 'AVG_PMT_CNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total Payment CNT\n",
    "grp = B[['SK_ID_CURR', 'CNT_PAYMENT']].groupby(by = ['SK_ID_CURR'])['CNT_PAYMENT'].sum().reset_index().rename(index=str, columns={'CNT_PAYMENT': 'TOTAL_PMT_CNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Avg Days Of Previous APP Decision\n",
    "grp = B[['SK_ID_CURR', 'DAYS_DECISION']].groupby(by = ['SK_ID_CURR'])['DAYS_DECISION'].mean().reset_index().rename(index=str, columns={'DAYS_DECISION': 'AVG_DAYS_OF_PRE_DEC'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: CLosest Day of Previous APP Decision\n",
    "grp = B[['SK_ID_CURR', 'DAYS_DECISION']].groupby(by = ['SK_ID_CURR'])['DAYS_DECISION'].max().reset_index().rename(index=str, columns={'DAYS_DECISION': 'MIN_DAYS_OF_PRE_DEC'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Avg Interest Priviledged\n",
    "grp = B[['SK_ID_CURR', 'RATE_INTEREST_PRIVILEGED']].groupby(by = ['SK_ID_CURR'])['RATE_INTEREST_PRIVILEGED'].mean().reset_index().rename(index=str, columns={'RATE_INTEREST_PRIVILEGED': 'AVG_INT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Avg Interest DOWN PMT RATE\n",
    "grp = B[['SK_ID_CURR', 'RATE_DOWN_PAYMENT']].groupby(by = ['SK_ID_CURR'])['RATE_DOWN_PAYMENT'].mean().reset_index().rename(index=str, columns={'RATE_DOWN_PAYMENT': 'AVG_DOWN_PMT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: MAX Approved Credit\n",
    "grp = B[['SK_ID_CURR', 'AMT_CREDIT', 'APPROVED']].groupby(by = ['SK_ID_CURR']).apply(lambda x: x[x['APPROVED']==1]['AMT_CREDIT'].max()).reset_index().rename(index=int, columns={0: 'MAX_APPROVED_CREDIT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "gc.collect()\n",
    "print(B2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338857, 26)\n"
     ]
    }
   ],
   "source": [
    "B3 = B2.groupby('SK_ID_CURR').first().reset_index()\n",
    "B3 = B3.replace([np.inf, -np.inf], np.nan)\n",
    "print(B3.shape)\n",
    "#B3.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive Correlations:\n",
      " AVG_PMT_CNT           0.0277\n",
      "AVG_INT               0.0311\n",
      "HIGH_INTEREST_COUNT   0.0369\n",
      "HIGH_INT_RATIO        0.0376\n",
      "NEW_LOAN_COUNT        0.0460\n",
      "AVG_DAYS_OF_PRE_DEC   0.0469\n",
      "REJECT_REASON_COUNT   0.0636\n",
      "REFUSED_LOAN_COUNT    0.0645\n",
      "REFUSED_RATIO         0.0777\n",
      "TARGET                1.0000\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Most Negative Correlations:\n",
      " APPROVE_REFUSE_RATIO   -0.0812\n",
      "APPROVED_RATIO         -0.0635\n",
      "LOW_INT_RATIO          -0.0544\n",
      "LOW_HIGH_INT_RATIO     -0.0431\n",
      "LOW_INTEREST_COUNT     -0.0351\n",
      "AVG_DOWN_PMT           -0.0336\n",
      "APPROVED_LOAN_COUNT    -0.0316\n",
      "MAX_APPROVED_CREDIT    -0.0276\n",
      "REPEAT_RATIO           -0.0214\n",
      "SK_ID_CURR             -0.0021\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df2 = df[['SK_ID_CURR','TARGET']]\n",
    "B4 = df2.merge(B3, on = ['SK_ID_CURR'], how = 'left')\n",
    "correlations = B4.corr()['TARGET'].sort_values()\n",
    "\n",
    "print('Most Positive Correlations:\\n', correlations.tail(10))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 147)\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(B3, on = ['SK_ID_CURR'], how = 'left')\n",
    "print(df.shape)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of integer features: 4\n",
      "# of float features: 8\n",
      "# of str features: 3\n"
     ]
    }
   ],
   "source": [
    "int_features = bureau.iloc[:, 2:].select_dtypes('int64').columns.values\n",
    "float_features = bureau.iloc[:, 2:].select_dtypes('float64').columns.values\n",
    "str_features = bureau.iloc[:, 2:].select_dtypes('O').columns.values\n",
    "\n",
    "print('# of integer features:', len(int_features))\n",
    "print('# of float features:', len(float_features))\n",
    "print('# of str features:', len(str_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREDIT_ACTIVE</th>\n",
       "      <th>CREDIT_CURRENCY</th>\n",
       "      <th>CREDIT_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1716428</td>\n",
       "      <td>1716428</td>\n",
       "      <td>1716428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Closed</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>Consumer credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1079273</td>\n",
       "      <td>1715020</td>\n",
       "      <td>1251615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CREDIT_ACTIVE CREDIT_CURRENCY      CREDIT_TYPE\n",
       "count        1716428         1716428          1716428\n",
       "unique             4               4               15\n",
       "top           Closed      currency 1  Consumer credit\n",
       "freq         1079273         1715020          1251615"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau.iloc[:, 2:].select_dtypes('O').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed     62.8790\n",
      "Active     36.7395\n",
      "Sold        0.3803\n",
      "Bad debt    0.0012\n",
      "Name: CREDIT_ACTIVE, dtype: float64\n",
      "currency 1   99.9180\n",
      "currency 2    0.0713\n",
      "currency 3    0.0101\n",
      "currency 4    0.0006\n",
      "Name: CREDIT_CURRENCY, dtype: float64\n",
      "Consumer credit                                72.9197\n",
      "Credit card                                    23.4321\n",
      "Car loan                                        1.6132\n",
      "Mortgage                                        1.0715\n",
      "Microloan                                       0.7232\n",
      "Loan for business development                   0.1151\n",
      "Another type of loan                            0.0593\n",
      "Unknown type of loan                            0.0323\n",
      "Loan for working capital replenishment          0.0273\n",
      "Cash loan (non-earmarked)                       0.0033\n",
      "Real estate loan                                0.0016\n",
      "Loan for the purchase of equipment              0.0011\n",
      "Loan for purchase of shares (margin lending)    0.0002\n",
      "Interbank credit                                0.0001\n",
      "Mobile operator loan                            0.0001\n",
      "Name: CREDIT_TYPE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in str_features:\n",
    "    print(bureau[i].value_counts(dropna=False) / len(bureau) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau['ACTIVE_LOAN'] = bureau['CREDIT_ACTIVE']=='Active'\n",
    "bureau['NON_ACTIVE_LOAN'] = bureau['CREDIT_ACTIVE']!='Active'\n",
    "#bureau=bureau.drop(['CREDIT_CURRENCY'],axis=1)\n",
    "bureau['CONSUMER_CREDIT'] = bureau['CREDIT_TYPE'].isin(['Consumer credit','Credit card','Car loan','Mortgage'])\n",
    "#bureau.loc[~bureau['CREDIT_TYPE'].isin(['Consumer credit']), 'CREDIT_TYPE'] = \"Business credit\"\n",
    "bureau['BUSINESS_CREDIT'] = bureau['CONSUMER_CREDIT']==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  AMT_CREDIT_MAX_OVERDUE  \\\n",
      "count         1610875.0000       1082775.0000             591940.0000   \n",
      "mean              510.5174         -1017.4371               3825.4177   \n",
      "std              4994.2198           714.0106             206031.6062   \n",
      "min            -42060.0000        -42023.0000                  0.0000   \n",
      "25%             -1138.0000         -1489.0000                  0.0000   \n",
      "50%              -330.0000          -897.0000                  0.0000   \n",
      "75%               474.0000          -425.0000                  0.0000   \n",
      "max             31199.0000             0.0000          115987185.0000   \n",
      "\n",
      "       AMT_CREDIT_SUM  AMT_CREDIT_SUM_DEBT  AMT_CREDIT_SUM_LIMIT  \\\n",
      "count    1716415.0000         1458759.0000          1124648.0000   \n",
      "mean      354994.5919          137085.1200             6229.5150   \n",
      "std      1149811.3440          677401.1310            45032.0315   \n",
      "min            0.0000        -4705600.3200          -586406.1150   \n",
      "25%        51300.0000               0.0000                0.0000   \n",
      "50%       125518.5000               0.0000                0.0000   \n",
      "75%       315000.0000           40153.5000                0.0000   \n",
      "max    585000000.0000       170100000.0000          4705600.3200   \n",
      "\n",
      "       AMT_CREDIT_SUM_OVERDUE    AMT_ANNUITY  \n",
      "count            1716428.0000    489637.0000  \n",
      "mean                  37.9128     15712.7577  \n",
      "std                 5937.6500    325826.9491  \n",
      "min                    0.0000         0.0000  \n",
      "25%                    0.0000         0.0000  \n",
      "50%                    0.0000         0.0000  \n",
      "75%                    0.0000     13500.0000  \n",
      "max              3756681.0000 118453423.5000  \n"
     ]
    }
   ],
   "source": [
    "def plot_triaxes(df_in):\n",
    "    fig, axes = plt.subplots(len(df_in.columns)//2, 2, figsize=(12, 12))\n",
    "    i = 0\n",
    "    for triaxis in axes:\n",
    "        for axis in triaxis:\n",
    "            df_in.hist(column = df_in.columns[i], bins = 60, ax=axis)\n",
    "            i = i+1\n",
    "\n",
    "#plot_triaxes(bureau.iloc[:, 2:].select_dtypes('float64'))\n",
    "print(bureau.iloc[:, 2:].select_dtypes('float64').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove nagative values DAYS_CREDIT_ENDDATE because we don't need duration of nonactive loans and we already have  DAYS_ENDDATE_FACT for closed loans.\n",
    "\n",
    "Remove negative amounts for all of these AMT data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  AMT_CREDIT_MAX_OVERDUE  \\\n",
      "count          603486.0000       1082775.0000             591940.0000   \n",
      "mean             3106.7260         -1017.4371               3825.4177   \n",
      "std              7384.7634           714.0106             206031.6062   \n",
      "min                 0.0000        -42023.0000                  0.0000   \n",
      "25%               323.0000         -1489.0000                  0.0000   \n",
      "50%               790.0000          -897.0000                  0.0000   \n",
      "75%              1386.0000          -425.0000                  0.0000   \n",
      "max             31199.0000             0.0000          115987185.0000   \n",
      "\n",
      "       AMT_CREDIT_SUM  AMT_CREDIT_SUM_DEBT  AMT_CREDIT_SUM_LIMIT  \\\n",
      "count    1716415.0000         1450341.0000          1124297.0000   \n",
      "mean      354994.5919          137926.1187             6238.8775   \n",
      "std      1149811.3440          679233.8310            45022.3336   \n",
      "min            0.0000               0.0000                0.0000   \n",
      "25%        51300.0000               0.0000                0.0000   \n",
      "50%       125518.5000               0.0000                0.0000   \n",
      "75%       315000.0000           41400.0000                0.0000   \n",
      "max    585000000.0000       170100000.0000          4705600.3200   \n",
      "\n",
      "       AMT_CREDIT_SUM_OVERDUE    AMT_ANNUITY  \n",
      "count            1716428.0000    489637.0000  \n",
      "mean                  37.9128     15712.7577  \n",
      "std                 5937.6500    325826.9491  \n",
      "min                    0.0000         0.0000  \n",
      "25%                    0.0000         0.0000  \n",
      "50%                    0.0000         0.0000  \n",
      "75%                    0.0000     13500.0000  \n",
      "max              3756681.0000 118453423.5000  \n"
     ]
    }
   ],
   "source": [
    "#bureau.mask(bureau.sub(bureau.mean()).div(bureau.std()).abs().gt(3))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "bureau['DAYS_CREDIT_ENDDATE'][bureau['DAYS_CREDIT_ENDDATE'] < 0] = np.nan\n",
    "bureau['AMT_CREDIT_SUM_OVERDUE'][bureau['AMT_CREDIT_SUM_OVERDUE'] < 0] = np.nan\n",
    "bureau['AMT_ANNUITY'][bureau['AMT_ANNUITY'] < 0] = np.nan\n",
    "bureau['AMT_CREDIT_SUM_LIMIT'][bureau['AMT_CREDIT_SUM_LIMIT'] < 0] = np.nan\n",
    "bureau['AMT_CREDIT_SUM_DEBT'][bureau['AMT_CREDIT_SUM_DEBT'] < 0] = np.nan\n",
    "bureau['AMT_CREDIT_SUM'][bureau['AMT_CREDIT_SUM'] < 0] = np.nan\n",
    "bureau['AMT_CREDIT_MAX_OVERDUE'][bureau['AMT_CREDIT_MAX_OVERDUE'] < 0] = np.nan\n",
    "print(bureau.iloc[:, 2:].select_dtypes('float64').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DAYS_CREDIT  CREDIT_DAY_OVERDUE  CNT_CREDIT_PROLONG  DAYS_CREDIT_UPDATE\n",
      "count 1716428.0000        1716428.0000        1716428.0000        1716428.0000\n",
      "mean    -1142.1077              0.8182              0.0064           -593.7483\n",
      "std       795.1649             36.5444              0.0962            720.7473\n",
      "min     -2922.0000              0.0000              0.0000         -41947.0000\n",
      "25%     -1666.0000              0.0000              0.0000           -908.0000\n",
      "50%      -987.0000              0.0000              0.0000           -395.0000\n",
      "75%      -474.0000              0.0000              0.0000            -33.0000\n",
      "max         0.0000           2792.0000              9.0000            372.0000\n"
     ]
    }
   ],
   "source": [
    "print(bureau.iloc[:, 2:].select_dtypes('int64').describe())\n",
    "def plot_triaxes(df_in):\n",
    "    fig, axes = plt.subplots(len(df_in.columns)//2, 2, figsize=(12, 12))\n",
    "    i = 0\n",
    "    for triaxis in axes:\n",
    "        for axis in triaxis:\n",
    "            df_in.hist(column = df_in.columns[i], bins = 60, ax=axis)\n",
    "            i = i+1\n",
    "#plot_triaxes(bureau.iloc[:, 2:].select_dtypes('int64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed positive values for DAYS_CREDIT_UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DAYS_CREDIT  CREDIT_DAY_OVERDUE  CNT_CREDIT_PROLONG\n",
      "count 1716428.0000        1716428.0000        1716428.0000\n",
      "mean    -1142.1077              0.8182              0.0064\n",
      "std       795.1649             36.5444              0.0962\n",
      "min     -2922.0000              0.0000              0.0000\n",
      "25%     -1666.0000              0.0000              0.0000\n",
      "50%      -987.0000              0.0000              0.0000\n",
      "75%      -474.0000              0.0000              0.0000\n",
      "max         0.0000           2792.0000              9.0000\n"
     ]
    }
   ],
   "source": [
    "bureau['DAYS_CREDIT_UPDATE'][bureau['DAYS_CREDIT_UPDATE'] > 0] = np.nan\n",
    "print(bureau.iloc[:, 2:].select_dtypes('int64').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1716428, 16)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect\n",
    "\n",
    "B = bureau\n",
    "B2 = bureau.SK_ID_CURR\n",
    "\n",
    "# Feature: Total # of Bureau Loans\n",
    "grp = B[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby(by = ['SK_ID_CURR'])['SK_ID_BUREAU'].count().reset_index().rename(index=str, columns={'SK_ID_BUREAU': 'BUREAU_LOAN_COUNT'})\n",
    "B2 = B2.to_frame().merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of Active Bureau Loans\n",
    "grp = B[['SK_ID_CURR', 'ACTIVE_LOAN']].groupby(by = ['SK_ID_CURR'])['ACTIVE_LOAN'].sum().reset_index().rename(index=str, columns={'ACTIVE_LOAN': 'ACTIVE_LOAN_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of Business Bureau Loans\n",
    "grp = B[['SK_ID_CURR', 'BUSINESS_CREDIT']].groupby(by = ['SK_ID_CURR'])['BUSINESS_CREDIT'].sum().reset_index().rename(index=str, columns={'BUSINESS_CREDIT': 'BUSINESS_LOAN_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Total # of Loan Types\n",
    "grp = B[['SK_ID_CURR', 'CREDIT_TYPE']].groupby(by = ['SK_ID_CURR'])['CREDIT_TYPE'].nunique().reset_index().rename(index=str, columns={'CREDIT_TYPE': 'BUREAU_LOAN_TYPES_COUNT'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Avg # Loans Per Loan Types\n",
    "B2['AVERAGE_LOAN_TYPE'] = B2['BUREAU_LOAN_COUNT']/B2['BUREAU_LOAN_TYPES_COUNT']\n",
    "\n",
    "# Feature: % Active Loans\n",
    "B2['ACTIVE_PERCENT'] = B2['ACTIVE_LOAN_COUNT']/B2['BUREAU_LOAN_COUNT']\n",
    "\n",
    "# Feature: % Business Loans\n",
    "B2['BUSINESS_PERCENT'] = B2['BUSINESS_LOAN_COUNT']/B2['BUREAU_LOAN_COUNT']\n",
    "\n",
    "# Feature: Avg Duration of Active Loans\n",
    "grp = B[['SK_ID_CURR', 'DAYS_CREDIT_ENDDATE']].groupby(by = ['SK_ID_CURR'])['DAYS_CREDIT_ENDDATE'].mean().reset_index().rename(index=str, columns={'DAYS_CREDIT_ENDDATE': 'AVG_ACTIVE_DURATION'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature: Avg Days Past of Closed Loans\n",
    "grp = B[['SK_ID_CURR', 'DAYS_ENDDATE_FACT']].groupby(by = ['SK_ID_CURR'])['DAYS_ENDDATE_FACT'].mean().reset_index().rename(index=str, columns={'DAYS_ENDDATE_FACT': 'AVG_DAYS_PAST_CLOSED_LOAN'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "# Feature : Debt Over Credit Limit Ratio\n",
    "B['AMT_CREDIT_SUM_DEBT'] = B['AMT_CREDIT_SUM_DEBT'].fillna(0)\n",
    "B['AMT_CREDIT_SUM'] = B['AMT_CREDIT_SUM'].fillna(0)\n",
    "\n",
    "grp1 = B[['SK_ID_CURR', 'AMT_CREDIT_SUM_DEBT']].groupby(by = ['SK_ID_CURR'])['AMT_CREDIT_SUM_DEBT'].sum().reset_index().rename( index = str, columns = { 'AMT_CREDIT_SUM_DEBT': 'TOTAL_CUSTOMER_DEBT'})\n",
    "grp2 = B[['SK_ID_CURR', 'AMT_CREDIT_SUM']].groupby(by = ['SK_ID_CURR'])['AMT_CREDIT_SUM'].sum().reset_index().rename( index = str, columns = { 'AMT_CREDIT_SUM': 'TOTAL_CUSTOMER_CREDIT'})\n",
    "\n",
    "B2 = B2.merge(grp1, on = ['SK_ID_CURR'], how = 'left')\n",
    "B2 = B2.merge(grp2, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "gc.collect()\n",
    "B2['TOTAL_DEBT_CREDIT_RATIO'] = B2['TOTAL_CUSTOMER_DEBT']/B2['TOTAL_CUSTOMER_CREDIT']\n",
    "\n",
    "# Feature : Overdue Over Debt Ratio\n",
    "\n",
    "B['AMT_CREDIT_SUM_OVERDUE'] = B['AMT_CREDIT_SUM_OVERDUE'].fillna(0)\n",
    "\n",
    "grp1 = B[['SK_ID_CURR', 'AMT_CREDIT_SUM_OVERDUE']].groupby(by = ['SK_ID_CURR'])['AMT_CREDIT_SUM_OVERDUE'].sum().reset_index().rename( index = str, columns = { 'AMT_CREDIT_SUM_OVERDUE': 'TOTAL_CUSTOMER_OVERDUE'})\n",
    "\n",
    "B2 = B2.merge(grp1, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "B2['TOTAL_OVERDUE_DEBT_RATIO'] = B2['TOTAL_CUSTOMER_OVERDUE']/B2['TOTAL_CUSTOMER_DEBT']\n",
    "\n",
    "#B2['DEBT_CREDIT_RATIO'][B2['DEBT_CREDIT_RATIO'] > 10] = np.nan\n",
    "\n",
    "# Feature: Total # of Credits Prolonged\n",
    "grp = B[['SK_ID_CURR', 'CNT_CREDIT_PROLONG']].groupby(by = ['SK_ID_CURR'])['CNT_CREDIT_PROLONG'].count().reset_index().rename(index=str, columns={'CNT_CREDIT_PROLONG': 'TOTAL_CREDIT_PROLONG'})\n",
    "B2 = B2.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "gc.collect()\n",
    "print(B2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: Total # of Bureau Loans\n",
    "grp1 = B[['SK_ID_CURR', 'CNT_CREDIT_PROLONG', 'ACTIVE_LOAN']].groupby(by = ['SK_ID_CURR']).apply(lambda x: x[x['ACTIVE_LOAN']==1]['CNT_CREDIT_PROLONG'].count()).reset_index().rename(index=int, columns={0: 'ACTIVE_CREDIT_PROLONG'})\n",
    "grp2 = B[['SK_ID_CURR', 'SK_ID_BUREAU', 'CREDIT_ACTIVE']].groupby(by = ['SK_ID_CURR']).apply(lambda x: x[x['CREDIT_ACTIVE']=='Bad debt']['SK_ID_BUREAU'].count()).reset_index().rename(index=int, columns={0: 'TOTAL_BAD_DEBT'})\n",
    "grp3 = B[['SK_ID_CURR', 'SK_ID_BUREAU', 'CREDIT_ACTIVE']].groupby(by = ['SK_ID_CURR']).apply(lambda x: x[x['CREDIT_ACTIVE']=='Sold']['SK_ID_BUREAU'].count()).reset_index().rename(index=int, columns={0: 'TOTAL_SOLD_DEBT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1716428, 21)\n"
     ]
    }
   ],
   "source": [
    "B2 = B2.merge(grp1, on = ['SK_ID_CURR'], how = 'left')\n",
    "B2 = B2.merge(grp2, on = ['SK_ID_CURR'], how = 'left')\n",
    "B2 = B2.merge(grp3, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "B2['BAD_PERCENT'] = B2['TOTAL_BAD_DEBT']/B2['BUREAU_LOAN_COUNT']\n",
    "B2['SOLD_PERCENT'] = B2['TOTAL_SOLD_DEBT']/B2['BUREAU_LOAN_COUNT']\n",
    "gc.collect()\n",
    "print(B2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305811, 21)\n"
     ]
    }
   ],
   "source": [
    "B3 = B2.groupby('SK_ID_CURR').first().reset_index()\n",
    "B3 = B3.replace([np.inf, -np.inf], np.nan)\n",
    "print(B3.shape)\n",
    "#B3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET                       1.0000\n",
       "TOTAL_DEBT_CREDIT_RATIO      0.0920\n",
       "ACTIVE_PERCENT               0.0774\n",
       "ACTIVE_LOAN_COUNT            0.0671\n",
       "ACTIVE_CREDIT_PROLONG        0.0671\n",
       "AVG_DAYS_PAST_CLOSED_LOAN    0.0532\n",
       "BUSINESS_PERCENT             0.0348\n",
       "BUSINESS_LOAN_COUNT          0.0321\n",
       "AVG_ACTIVE_DURATION          0.0170\n",
       "SOLD_PERCENT                 0.0165\n",
       "TOTAL_CUSTOMER_OVERDUE       0.0133\n",
       "TOTAL_SOLD_DEBT              0.0121\n",
       "TOTAL_CUSTOMER_DEBT          0.0071\n",
       "BAD_PERCENT                  0.0046\n",
       "BUREAU_LOAN_TYPES_COUNT      0.0046\n",
       "TOTAL_CREDIT_PROLONG         0.0041\n",
       "BUREAU_LOAN_COUNT            0.0041\n",
       "TOTAL_BAD_DEBT               0.0040\n",
       "TOTAL_OVERDUE_DEBT_RATIO     0.0009\n",
       "SK_ID_CURR                  -0.0021\n",
       "AVERAGE_LOAN_TYPE           -0.0061\n",
       "TOTAL_CUSTOMER_CREDIT       -0.0141\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B4 = df[['SK_ID_CURR','TARGET']]\n",
    "B4 = B4.merge(B3, on = ['SK_ID_CURR'], how = 'left')\n",
    "correlations = B4.corr()['TARGET'].sort_values(ascending=False)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 167)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_CUSTOMER_CREDIT</th>\n",
       "      <th>TOTAL_DEBT_CREDIT_RATIO</th>\n",
       "      <th>TOTAL_CUSTOMER_OVERDUE</th>\n",
       "      <th>TOTAL_OVERDUE_DEBT_RATIO</th>\n",
       "      <th>TOTAL_CREDIT_PROLONG</th>\n",
       "      <th>ACTIVE_CREDIT_PROLONG</th>\n",
       "      <th>TOTAL_BAD_DEBT</th>\n",
       "      <th>TOTAL_SOLD_DEBT</th>\n",
       "      <th>BAD_PERCENT</th>\n",
       "      <th>SOLD_PERCENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0000</td>\n",
       "      <td>406597.5000</td>\n",
       "      <td>24700.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>865055.5650</td>\n",
       "      <td>0.2841</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0000</td>\n",
       "      <td>1293502.5000</td>\n",
       "      <td>35698.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>1017400.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0000</td>\n",
       "      <td>135000.0000</td>\n",
       "      <td>6750.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>189037.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0000</td>\n",
       "      <td>312682.5000</td>\n",
       "      <td>29686.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0000</td>\n",
       "      <td>513000.0000</td>\n",
       "      <td>21865.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>146250.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL   AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0       202500.0000  406597.5000   24700.5000   \n",
       "1               N             0       270000.0000 1293502.5000   35698.5000   \n",
       "2               Y             0        67500.0000  135000.0000    6750.0000   \n",
       "3               Y             0       135000.0000  312682.5000   29686.5000   \n",
       "4               Y             0       121500.0000  513000.0000   21865.5000   \n",
       "\n",
       "   ...  TOTAL_CUSTOMER_CREDIT TOTAL_DEBT_CREDIT_RATIO TOTAL_CUSTOMER_OVERDUE  \\\n",
       "0  ...            865055.5650                  0.2841                 0.0000   \n",
       "1  ...           1017400.5000                  0.0000                 0.0000   \n",
       "2  ...            189037.8000                  0.0000                 0.0000   \n",
       "3  ...                    nan                     nan                    nan   \n",
       "4  ...            146250.0000                  0.0000                 0.0000   \n",
       "\n",
       "  TOTAL_OVERDUE_DEBT_RATIO TOTAL_CREDIT_PROLONG ACTIVE_CREDIT_PROLONG  \\\n",
       "0                   0.0000               8.0000                2.0000   \n",
       "1                      nan               4.0000                1.0000   \n",
       "2                      nan               2.0000                0.0000   \n",
       "3                      nan                  nan                   nan   \n",
       "4                      nan               1.0000                0.0000   \n",
       "\n",
       "   TOTAL_BAD_DEBT  TOTAL_SOLD_DEBT  BAD_PERCENT  SOLD_PERCENT  \n",
       "0          0.0000           0.0000       0.0000        0.0000  \n",
       "1          0.0000           0.0000       0.0000        0.0000  \n",
       "2          0.0000           0.0000       0.0000        0.0000  \n",
       "3             nan              nan          nan           nan  \n",
       "4          0.0000           0.0000       0.0000        0.0000  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B5 = B2[['SK_ID_CURR','ACTIVE_LOAN_COUNT','BUSINESS_LOAN_COUNT','ACTIVE_PERCENT','BUSINESS_PERCENT',\n",
    "#          'AVG_ACTIVE_DURATION','AVG_DAYS_PAST_CLOSED_LOAN','DEBT_CREDIT_RATIO'\n",
    "#         ]]\n",
    "df = df.merge(B3, on = ['SK_ID_CURR'], how = 'left')\n",
    "print(df.shape)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DAYS_EMPLOYED_ANOM'] = df['DAYS_EMPLOYED'] == 365243\n",
    "df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "df['DAYS_EMPLOYED_ANOM'] = df['DAYS_EMPLOYED_ANOM'].astype(int)\n",
    "df['APP_CREDIT_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "df['CURRENT_CREDIT_INCOME_RATIO'] = df['TOTAL_CUSTOMER_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "df['CURRENT_DEBT_INCOME_RATIO'] = df['TOTAL_CUSTOMER_DEBT'] / df['AMT_INCOME_TOTAL']\n",
    "df['ANNUITY_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "df['CREDIT_TERM'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "df['DAYS_EMPLOYED_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['APP_CREDIT_MAX_APPROVED_RATIO'] = df['AMT_CREDIT'] / df['MAX_APPROVED_CREDIT']\n",
    "df = df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive Correlations:\n",
      " DAYS_ID_PUBLISH               0.0515\n",
      "AVG_DAYS_PAST_CLOSED_LOAN     0.0532\n",
      "DAYS_LAST_PHONE_CHANGE        0.0552\n",
      "REGION_RATING_CLIENT          0.0589\n",
      "REGION_RATING_CLIENT_W_CITY   0.0609\n",
      "REJECT_REASON_COUNT           0.0636\n",
      "REFUSED_LOAN_COUNT            0.0645\n",
      "ACTIVE_CREDIT_PROLONG         0.0671\n",
      "ACTIVE_LOAN_COUNT             0.0671\n",
      "DAYS_EMPLOYED                 0.0750\n",
      "ACTIVE_PERCENT                0.0774\n",
      "REFUSED_RATIO                 0.0777\n",
      "DAYS_BIRTH                    0.0782\n",
      "TOTAL_DEBT_CREDIT_RATIO       0.0920\n",
      "TARGET                        1.0000\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Most Negative Correlations:\n",
      " EXT_SOURCE_3                 -0.1789\n",
      "EXT_SOURCE_2                 -0.1605\n",
      "EXT_SOURCE_1                 -0.1553\n",
      "APPROVE_REFUSE_RATIO         -0.0812\n",
      "DAYS_EMPLOYED_RATIO          -0.0680\n",
      "APPROVED_RATIO               -0.0635\n",
      "LOW_INT_RATIO                -0.0544\n",
      "DAYS_EMPLOYED_ANOM           -0.0460\n",
      "FLOORSMAX_AVG                -0.0440\n",
      "FLOORSMAX_MEDI               -0.0438\n",
      "FLOORSMAX_MODE               -0.0432\n",
      "LOW_HIGH_INT_RATIO           -0.0431\n",
      "AMT_GOODS_PRICE              -0.0396\n",
      "REGION_POPULATION_RELATIVE   -0.0372\n",
      "LOW_INTEREST_COUNT           -0.0351\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlations = df.corr()['TARGET'].sort_values()\n",
    "\n",
    "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Features shape:  (307511, 113)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH',\n",
    "                    'TOTAL_DEBT_CREDIT_RATIO','ACTIVE_LOAN_COUNT','REFUSED_LOAN_COUNT'\n",
    "                   ]]\n",
    "\n",
    "# imputer for handling missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "poly_features = imputer.fit_transform(poly_features)\n",
    "\n",
    "# Create the polynomial object with specified degree\n",
    "poly_transformer = PolynomialFeatures(degree = 3)\n",
    "poly_features=poly_transformer.fit_transform(poly_features)\n",
    "\n",
    "poly_features = pd.DataFrame(poly_features, \n",
    "                             columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', \n",
    "                                                                           'DAYS_BIRTH','TOTAL_DEBT_CREDIT_RATIO','ACTIVE_LOAN_COUNT','REFUSED_LOAN_COUNT'\n",
    "                                                                          ]))\n",
    "\n",
    "poly_features=poly_features.drop(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH',\n",
    "                                     'TOTAL_DEBT_CREDIT_RATIO','ACTIVE_LOAN_COUNT','REFUSED_LOAN_COUNT'\n",
    "                                 ], axis=1)\n",
    "\n",
    "# Transform the features\n",
    "gc.collect()\n",
    "print('Polynomial Features shape: ', poly_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features['SK_ID_CURR'] = df['SK_ID_CURR']\n",
    "df = df.merge(poly_features, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive Correlations:\n",
      " DAYS_BIRTH                                    0.0782\n",
      "TOTAL_DEBT_CREDIT_RATIO^2 ACTIVE_LOAN_COUNT   0.0809\n",
      "TOTAL_DEBT_CREDIT_RATIO ACTIVE_LOAN_COUNT     0.0898\n",
      "TOTAL_DEBT_CREDIT_RATIO                       0.0920\n",
      "EXT_SOURCE_1^2 DAYS_BIRTH                     0.0975\n",
      "EXT_SOURCE_1 DAYS_BIRTH                       0.1049\n",
      "EXT_SOURCE_3^2 DAYS_BIRTH                     0.1418\n",
      "EXT_SOURCE_2^2 DAYS_BIRTH                     0.1493\n",
      "EXT_SOURCE_3 DAYS_BIRTH                       0.1501\n",
      "EXT_SOURCE_1 EXT_SOURCE_3 DAYS_BIRTH          0.1518\n",
      "EXT_SOURCE_1 EXT_SOURCE_2 DAYS_BIRTH          0.1559\n",
      "EXT_SOURCE_2 DAYS_BIRTH                       0.1569\n",
      "EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH          0.1813\n",
      "TARGET                                        1.0000\n",
      "1                                                nan\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Most Negative Correlations:\n",
      " EXT_SOURCE_2 EXT_SOURCE_3                -0.1939\n",
      "EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3   -0.1896\n",
      "EXT_SOURCE_3                             -0.1789\n",
      "EXT_SOURCE_2^2 EXT_SOURCE_3              -0.1764\n",
      "EXT_SOURCE_2 EXT_SOURCE_3^2              -0.1723\n",
      "EXT_SOURCE_1 EXT_SOURCE_2                -0.1666\n",
      "EXT_SOURCE_1 EXT_SOURCE_3                -0.1641\n",
      "EXT_SOURCE_2                             -0.1605\n",
      "EXT_SOURCE_1 EXT_SOURCE_2^2              -0.1569\n",
      "EXT_SOURCE_1                             -0.1553\n",
      "EXT_SOURCE_1 EXT_SOURCE_3^2              -0.1508\n",
      "EXT_SOURCE_2^2                           -0.1495\n",
      "EXT_SOURCE_3^2                           -0.1417\n",
      "EXT_SOURCE_2^3                           -0.1402\n",
      "EXT_SOURCE_1^2 EXT_SOURCE_2              -0.1402\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlations = df.corr()['TARGET'].sort_values()\n",
    "\n",
    "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('fivethirtyeight')\n",
    "\n",
    "# # Plot the distribution of ages in years\n",
    "# plt.hist(df['ACTIVE_PERCENT'], edgecolor = 'k', bins = 50)\n",
    "# plt.title('ACTIVE_PERCENT'); plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVZF3mpugJ5m"
   },
   "source": [
    "# Process and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aoPvJHoJeqX-",
    "outputId": "0633743e-9fa2-472b-fbf1-97eb60be33ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 288)\n",
      "# of integer features: 38\n",
      "# of float features: 231\n",
      "# of str features: 16\n"
     ]
    }
   ],
   "source": [
    "# check for category of features\n",
    "int_features = df.iloc[:, 2:].select_dtypes('int64').columns.values\n",
    "float_features = df.iloc[:, 2:].select_dtypes('float64').columns.values\n",
    "str_features = df.iloc[:, 2:].select_dtypes('O').columns.values\n",
    "print(df.shape)\n",
    "print('# of integer features:', len(int_features))\n",
    "print('# of float features:', len(float_features))\n",
    "print('# of str features:', len(str_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "4CBLLC_-eqX_"
   },
   "outputs": [],
   "source": [
    "# Divide features into numerical and categorical\n",
    "num_features = np.hstack([int_features, float_features])\n",
    "cat_features = str_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "WbO5QCmzmsF3"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# positives = df.TARGET == 1\n",
    "# negatives = ~positives\n",
    "# neg_df = df.loc[negatives]\n",
    "# balanced_df = pd.concat([neg_df.sample(sum(positives)),df.loc[positives]])\n",
    "# y = balanced_df.TARGET\n",
    "# X = balanced_df.drop('TARGET',axis=1)\n",
    "\n",
    "# X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.10, random_state=42, stratify=y)\n",
    "# X_train_raw, X_dev_raw, y_train, y_dev = train_test_split(\n",
    "#     X_train_raw, y_train, test_size=1/9., random_state=42, \n",
    "#     stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balance of positive and negative classes of train:\n",
      "0   91.9271\n",
      "1    8.0729\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Dev:\n",
      "0   91.9287\n",
      "1    8.0713\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Test:\n",
      "0   91.9257\n",
      "1    8.0743\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['TARGET','SK_ID_CURR'], axis = 1)\n",
    "y = df.TARGET\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "X_train_raw, X_dev_raw, y_train, y_dev = train_test_split(\n",
    "    X_train_raw, y_train,\n",
    "    test_size=1/9.,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "\n",
    "print('\\nBalance of positive and negative classes of train:')\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\nDev:')      \n",
    "print(y_dev.value_counts(normalize=True) * 100)\n",
    "      \n",
    "print('\\nTest:')\n",
    "print(y_test.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "A6bxh7WMeqYA"
   },
   "outputs": [],
   "source": [
    "# Using pipeline to feature scale numerical values, and hot encode categorical values\n",
    "num_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())  \n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ], \n",
    "    sparse_threshold=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcYUUgcMeqYA",
    "outputId": "eafc020c-f7c3-461b-e89c-ceddf987ae37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (246008, 415)\n",
      "y_train shape: (246008,)\n",
      "X_dev shape: (30751, 415)\n",
      "y_dev shape: (30751,)\n",
      "X_test shape:  (30752, 415)\n",
      "y_test shape:  (30752,)\n"
     ]
    }
   ],
   "source": [
    "# Tranform the training data, and use the information from the training data to transform test data so we don't contaminate it. \n",
    "preprocessor.fit(X_train_raw)\n",
    "X_train = preprocessor.transform(X_train_raw)\n",
    "X_dev = preprocessor.transform(X_dev_raw)\n",
    "X_test = preprocessor.transform(X_test_raw)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_dev shape:', X_dev.shape)\n",
    "print('y_dev shape:', y_dev.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X before SMOTE: (246008, 415)\n",
      "Shape of X after SMOTE: (452296, 415)\n",
      "\n",
      "Balance of positive and negative classes (%):\n",
      "0   91.9271\n",
      "1    8.0729\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Balance of positive and negative classes (%):\n",
      "1   50.0000\n",
      "0   50.0000\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "gc.collect\n",
    "print(f'''Shape of X before SMOTE: {X_train.shape}\n",
    "Shape of X after SMOTE: {X_resampled.shape}''')\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(y_resampled.value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_train_data, mini_train_labels = X_train[:5000], y_train[:5000]\n",
    "# print('X_train shape:', mini_train_data.shape)\n",
    "# print('y_train shape:', mini_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of C is:  9.0 Max AUC-score:  0.771\n",
      "Wall time: 14min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "c_values = [i*1 for i in range(1,11)]\n",
    "AUC_list = []\n",
    "#print(\"C Value\",\", \",\"AUC-Score\")\n",
    "for c in c_values:\n",
    "    clf = LR(C = c, solver='liblinear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    #pred = clf.predict(X_dev)\n",
    "    AUC_score = roc_auc_score(y_dev,  clf.predict_proba(X_dev)[:,1])\n",
    "    AUC_list.append(AUC_score)\n",
    "    #print(c, round(AUC_score,4))\n",
    "\n",
    "# Identifying the maximum value of F1 and its respective 'C' value:\n",
    "max_AUC = max(AUC_list)\n",
    "index = AUC_list.index(max_AUC)\n",
    "best_c = index/1\n",
    "\n",
    "print(\"The best value of C is: \", best_c, \"Max AUC-score: \", round(max_AUC,4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Dev AUC: 0.7628\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "X, y = X_train, y_train\n",
    "X2,y2 = X_dev, y_dev\n",
    "\n",
    "LR_mod = LR(C = 9, solver='liblinear')\n",
    "LR_mod.fit(X, y)\n",
    "\n",
    "print('Logistic Regression Dev AUC: %.4f' %  \n",
    "      roc_auc_score(y2, LR_mod.predict_proba(X2)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression as LR\n",
    "# X, y = X_resampled_fs, y_resampled\n",
    "# X2,y2 = X_dev_fs, y_dev\n",
    "\n",
    "# LR_mod = LR(C = 1, solver='liblinear')\n",
    "# LR_mod.fit(X, y)\n",
    "\n",
    "# gc.collect\n",
    "# print('Logistic Regression Dev AUC: %.3f' %  \n",
    "#       roc_auc_score(y2, LR_mod.predict_proba(X2)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "X, y = X_train, y_train\n",
    "\n",
    "title = \"Learning Curves (LR with Poly)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = LR(solver='liblinear')\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.65, 0.95),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "X, y = X_resampled, y_resampled\n",
    "\n",
    "title = \"Learning Curves (LR with Poly with FS)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = LR(solver='liblinear')\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.65, 0.95),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzorYGMNeqYB"
   },
   "source": [
    "# Tried and Failed Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier as RF\n",
    "# from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "# from sklearn.linear_model import LogisticRegression as LR\n",
    "# from sklearn.neural_network import MLPClassifier as MLP\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# estimator = LR(solver='liblinear')\n",
    "\n",
    "# selector = SelectFromModel(estimator,threshold=0.75*0.6440).fit(X_resampled, y_resampled)\n",
    "# print(\"Avg coefficient and threshold for feature selection\",selector.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled_fs = selector.transform(X_resampled)\n",
    "# X_train_fs = selector.transform(X_train)\n",
    "# X_dev_fs = selector.transform(X_dev)\n",
    "# X_test_fs = selector.transform(X_test)\n",
    "# print(\"%3.0f features before feature selection\"%(X_train.shape[1]))\n",
    "# print(\"%3.0f features after feature selection\"%(X_train_fs.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# # Create the polynomial object with specified degree\n",
    "# poly_transformer = PolynomialFeatures(degree = 2)\n",
    "# poly_transformer.fit(X_resampled_fs)\n",
    "\n",
    "# # Transform the features\n",
    "# X_resampled_fs_poly = poly_transformer.transform(X_resampled_fs)\n",
    "# X_train_fs_poly = poly_transformer.transform(X_train_fs)\n",
    "# X_dev_fs_poly = poly_transformer.transform(X_dev_fs)\n",
    "# X_test_fs_poly = poly_transformer.transform(X_test_fs)\n",
    "# print('Polynomial Features shape: ', X_train_fs_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = LR(solver='liblinear')\n",
    "# selector = SelectFromModel(estimator).fit(X_resampled_fs_poly, y_resampled)\n",
    "# print(\"Avg coefficient and threshold for feature selection\",selector.threshold_)\n",
    "\n",
    "# X_resampled_fs_poly_fs = selector.transform(X_resampled_fs_poly)\n",
    "# X_train_fs_poly_fs = selector.transform(X_train_fs_poly)\n",
    "# X_dev_fs_poly_fs = selector.transform(X_dev_fs_poly)\n",
    "# X_test_fs_poly_fs = selector.transform(X_test_fs_poly)\n",
    "# print(\"%3.0f features after feature selection\"%(X_train_fs_poly_fs.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb_22OEdA7J9"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhXtDEetXFVW"
   },
   "source": [
    "**We define a function to run cross validation for accuracy measurement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_train_data, mini_train_labels = X_train_fs_poly_fs[:5000], y_resampled[:5000]\n",
    "\n",
    "# print('X_train shape:', mini_train_data.shape)\n",
    "# print('y_train shape:', mini_train_labels.shape)\n",
    "# print('X_dev shape:', X_dev_fs_poly_fs.shape)\n",
    "# print('y_dev shape:', y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier as RF\n",
    "# from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "# from sklearn.linear_model import LogisticRegression as LR\n",
    "# from sklearn.neural_network import MLPClassifier as MLP\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# c_values = [i*0.1 for i in range(1,200)]\n",
    "# AUC_list = []\n",
    "# #print(\"C Value\",\", \",\"AUC-Score\")\n",
    "# for c in c_values:\n",
    "#     clf = LR(C = c, solver='liblinear')\n",
    "#     clf.fit(mini_train_data, mini_train_labels)\n",
    "#     #pred = clf.predict(X_dev)\n",
    "#     AUC_score = roc_auc_score(y_dev,  clf.predict_proba(X_dev_fs_poly_fs)[:,1])\n",
    "#     AUC_list.append(AUC_score)\n",
    "#     #print(c, round(AUC_score,4))\n",
    "\n",
    "# # Identifying the maximum value of F1 and its respective 'C' value:\n",
    "# max_AUC = max(AUC_list)\n",
    "# index = AUC_list.index(max_AUC)\n",
    "# best_c = index/10\n",
    "\n",
    "# print(\"The best value of C is: \", best_c, \"Max AUC-score: \", round(max_AUC,4)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRXXQmtmeqYC"
   },
   "source": [
    "**After balancing the classes through undersampling, we see that the Logistic regression narrowly edges out the Random Forest model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2N_rPH9eqYC",
    "outputId": "a2beffa6-0005-480e-ab40-23d50ceee045",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Using AUC to evaluate different ML algorithms learned in the class\n",
    "\n",
    "# from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# X, y = X_train_fs_poly, y_train\n",
    "# X2,y2 = X_dev_fs_poly, y_dev\n",
    "\n",
    "# LR_mod = LR(C = 1, solver='liblinear')\n",
    "# LR_proba = cross_val_predict(LR_mod, X, y, cv=5, method='predict_proba')[:,1]\n",
    "# print(\"Logistic regression AUC: %.3f\" % roc_auc_score(y, LR_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a final check with the dev data before submission\n",
    "#%%time\n",
    "\n",
    "# X, y = X_train_fs_poly, y_train\n",
    "# X2,y2 = X_dev_fs_poly, y_dev\n",
    "\n",
    "# LR_mod = LR(C = 1, solver='liblinear')\n",
    "# LR_mod.fit(X, y)\n",
    "\n",
    "# print('Logistic Regression Dev AUC: %.3f' %  \n",
    "#       roc_auc_score(y2, LR_mod.predict_proba(X2)[:,1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_3_Baseline_George, John, Kineret.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
